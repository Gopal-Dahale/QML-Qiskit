{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b40ea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:26:27.218724Z",
     "start_time": "2022-06-26T05:26:25.096492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "\n",
    "from qiskit import Aer, QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit.opflow import AerPauliExpectation\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# Set seed for random generators\n",
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974fca62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:26:29.951886Z",
     "start_time": "2022-06-26T05:26:28.390442Z"
    }
   },
   "outputs": [],
   "source": [
    "# declare quantum instance\n",
    "qi = QuantumInstance(Aer.get_backend(\"aer_simulator_statevector\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd2fc30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:26:30.072825Z",
     "start_time": "2022-06-26T05:26:29.956276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Additional torch-related imports\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d35955d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:26:30.226057Z",
     "start_time": "2022-06-26T05:26:30.076533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "# -------------\n",
    "\n",
    "# Set train shuffle seed (for reproducibility)\n",
    "manual_seed(42)\n",
    "\n",
    "batch_size = 1\n",
    "n_samples = 100  # We will concentrate on the first 100 samples\n",
    "\n",
    "# Use pre-defined torchvision function to load MNIST train data\n",
    "X_train = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Filter out labels (originally 0-9), leaving only labels 0 and 1\n",
    "idx = np.append(\n",
    "    np.where(X_train.targets == 0)[0][:n_samples], np.where(X_train.targets == 1)[0][:n_samples]\n",
    ")\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "# Define torch dataloader with filtered data\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b14ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:26:33.013522Z",
     "start_time": "2022-06-26T05:26:30.229749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComposedOp([\n",
      "  OperatorMeasurement(1.0 * ZZ),\n",
      "  CircuitStateFn(\n",
      "       ┌──────────────────────────┐┌──────────────────────────────────────┐\n",
      "  q_0: ┤0                         ├┤0                                     ├\n",
      "       │  ZZFeatureMap(x[0],x[1]) ││  RealAmplitudes(θ[0],θ[1],θ[2],θ[3]) │\n",
      "  q_1: ┤1                         ├┤1                                     ├\n",
      "       └──────────────────────────┘└──────────────────────────────────────┘\n",
      "  )\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "# Define and create QNN\n",
    "def create_qnn():\n",
    "    feature_map = ZZFeatureMap(2)\n",
    "    ansatz = RealAmplitudes(2, reps=1)\n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    qnn = TwoLayerQNN(\n",
    "        2,\n",
    "        feature_map,\n",
    "        ansatz,\n",
    "        input_gradients=True,\n",
    "        exp_val=AerPauliExpectation(),\n",
    "        quantum_instance=qi,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "\n",
    "qnn4 = create_qnn()\n",
    "print(qnn4.operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d128fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:27:08.436248Z",
     "start_time": "2022-06-26T05:27:08.411376Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define torch NN module\n",
    "\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self, qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 2, kernel_size=5)\n",
    "        self.conv2 = Conv2d(2, 16, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(256, 64)\n",
    "        self.fc2 = Linear(64, 2)  # 2-dimensional input to QNN\n",
    "        self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(1, 1)  # 1-dimensional output from QNN\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"INITIAL SHAPE:\", x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        print(\"SHAPE AFTER CONV2D:\", x.shape)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc3(x)\n",
    "        return cat((x, 1 - x), -1)\n",
    "\n",
    "\n",
    "model4 = Net(qnn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce0f5568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:27:37.777797Z",
     "start_time": "2022-06-26T05:27:08.960596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-15:\n",
      "FAILURE: Can not get job id, Resubmit the qobj to get job id. Terra job error: 'Keyboard interrupt in parallel_map.' \n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/enum.py\", line 289, in __call__\n",
      "    def __call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAILURE: Can not get job id, Resubmit the qobj to get job id. Terra job error: 'Keyboard interrupt in parallel_map.' \n",
      "Process ForkProcess-361:\n",
      "Process ForkProcess-362:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/gopald/.pyenv/versions/3.7.13/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "INITIAL SHAPE: torch.Size([1, 1, 28, 28])\n",
      "SHAPE AFTER CONV2D: torch.Size([1, 2, 24, 24])\n",
      "Training [100%]\tLoss: -0.9347\n"
     ]
    }
   ],
   "source": [
    "# Define model, optimizer, and loss function\n",
    "optimizer = optim.Adam(model4.parameters(), lr=0.001)\n",
    "loss_func = NLLLoss()\n",
    "\n",
    "# Start training\n",
    "epochs = 1  # Set number of epochs\n",
    "loss_list = []  # Store loss history\n",
    "model4.train()  # Set model to training mode\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "        output = model4(data)  # Forward pass\n",
    "        loss = loss_func(output, target)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize weights\n",
    "        total_loss.append(loss.item())  # Store loss\n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cf904a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T15:55:06.521745Z",
     "start_time": "2022-06-14T15:55:05.947010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss convergence\n",
    "plt.plot(loss_list)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Neg. Log Likelihood Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617cc9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qiskit-qcnn)",
   "language": "python",
   "name": "qiskit-qcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
